{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea140ec7",
   "metadata": {
    "id": "ea140ec7"
   },
   "source": [
    "# ECC4200 Project #1\n",
    "\n",
    "In this project, you are going to start an exciting journey to explore Deep Learning and Neural Networks by completing the following three tasks:\n",
    "\n",
    "* **Task 1. Understanding and conducting convolution (8%).**\n",
    "* **Task 2. Building and training a ResNet18 model (52%).**\n",
    "* **Task 3. Exploring and explaining the trained model (40%).**\n",
    "\n",
    "Before doing the project, please read the instructions carefully (failure to do so will be penalized):\n",
    "\n",
    "1. Implement your codes **within** \"TODO\" and \"END OF YOUR CODE\", do **NOT** modify any codes outside the answer area;\n",
    "2. Make sure your codes **clean**, **easily readable** (add meaningful comments if needed), and **runnable**;\n",
    "3. Write your answers in the given markdown cells, keep your answers clear and concise;\n",
    "4. Do submit your project before the deadline;\n",
    "5. Make sure that the **submitted notebooks have been run** and the **cell outputs are visible**.\n",
    "6. This is an individual project, do **NOT** share your solutions with others, we have zero tolerance for cheating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222f0884",
   "metadata": {
    "id": "222f0884"
   },
   "source": [
    "Note:\n",
    "\n",
    "1. It is recommended to do model training on GPU, you may use [Colab](https://colab.google/) or [Kaggle](https://www.kaggle.com/) for free computing resources for faster training.\n",
    "2. Since free computing resources accessible on [Colab](https://colab.google/) is limited for unsuscribed users for each day, it is recommended to debug on your CPU first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc14d01",
   "metadata": {
    "id": "ccc14d01"
   },
   "source": [
    "## Task 1: Understanding and conducting convolution (8%)\n",
    "**Subtasks**\n",
    "1. Use numpy to conduct 2D standard convolution operation (4%).\n",
    "2. Use numpy to conduct 2D dilated convolution operation (4%).\n",
    "\n",
    "You may refer to *[\"A guide to convolution arithmetic for deeplearning\"](https://arxiv.org/pdf/1603.07285.pdf)* for details of dilated convolution.\n",
    "\n",
    "In this task, we follow the settings as in the paper:\n",
    "* 2-D discrete convolutions,\n",
    "* square inputs,\n",
    "* square kernel size,\n",
    "* same strides along both axes,\n",
    "* same zero padding along both axes.\n",
    "\n",
    "Score points:\n",
    "1. The implementations are correct.\n",
    "2. The implementation of dilated convolution makes use of the relationship between dilated convolution kernel and standard convolution kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7279fa95",
   "metadata": {
    "id": "7279fa95"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e75e78",
   "metadata": {
    "id": "c0e75e78"
   },
   "outputs": [],
   "source": [
    "def conv2d(inputs,kernels,padding=0, stride=1):\n",
    "    assert inputs.shape[0] == kernels.shape[1], \"The numbers of channels of input and kernel do not match.\"\n",
    "    ##############################################################################\n",
    "    # TODO: conduct convolution calculation based on given inputs, kernels,      #\n",
    "    #       padding and stride values.                                           #\n",
    "    ##############################################################################\n",
    "    # your code\n",
    "\n",
    "\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc334c",
   "metadata": {
    "id": "56dc334c"
   },
   "outputs": [],
   "source": [
    "def dilated_conv2d(inputs,kernels,dilation,padding=0,stride=1):\n",
    "    assert inputs.shape[0] == kernels.shape[1], \"The numbers of channels of input and kernel do not match.\"\n",
    "    ##############################################################################\n",
    "    # TODO: conduct dilated convolution calculation based on given inputs,       #\n",
    "    #       kernels, padding and stride values.                                  #\n",
    "    ##############################################################################\n",
    "    # your code\n",
    "\n",
    "\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be16f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65be16f9",
    "outputId": "7da2d4be-3843-480c-cf60-e6d85abf127d"
   },
   "outputs": [],
   "source": [
    "np.random.seed(2024)\n",
    "inputs = np.random.randint(0,3,size=(2,5,5))\n",
    "kernels = np.random.randint(0,3,size=(3,2,2,2))\n",
    "print(f\"Inputs:\\n{inputs}\\n\")\n",
    "print(f\"Kernels:\\n{kernels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869672ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "869672ff",
    "outputId": "f0da849a-cfe3-4adf-85e2-4ceaff79fda9"
   },
   "outputs": [],
   "source": [
    "# visualize inputs\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in range(inputs.shape[0]):\n",
    "    ax = fig.add_subplot(1, inputs.shape[0], i+1, xticks=[], yticks=[])\n",
    "    ax.set_title('Input channel %s' % str(i+1))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.grid(True)\n",
    "    width = inputs[i].shape[0]\n",
    "    height = inputs[i].shape[1]\n",
    "\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(nbins=width))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(nbins=height))\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(inputs[i][x][y]), xy=(y/height+(0.5/height),x/width+(0.5/height)),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b7b25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760
    },
    "id": "197b7b25",
    "outputId": "9a74d9be-a048-4f6c-9b76-63494d20723c"
   },
   "outputs": [],
   "source": [
    "# visualize kernels\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 12))\n",
    "for i in range(kernels.shape[0]):\n",
    "    for j in range(kernels.shape[1]):\n",
    "        ax = fig.add_subplot(kernels.shape[0], kernels.shape[1], i*kernels.shape[1] + j+1, xticks=[], yticks=[])\n",
    "        ax.set_title(f'kernel {str(i+1)}, channel {str(j+1)}')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(True)\n",
    "        width = kernels[i][j].shape[0]\n",
    "        height = kernels[i][j].shape[1]\n",
    "\n",
    "\n",
    "        ax.xaxis.set_major_locator(plt.MaxNLocator(nbins=width))\n",
    "        ax.yaxis.set_major_locator(plt.MaxNLocator(nbins=height))\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                ax.annotate(str(kernels[i][j][x][y]), xy=(y/height+(0.5/height),x/width+(0.5/height)),\n",
    "                            horizontalalignment='center',\n",
    "                            verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64868dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f64868dd",
    "outputId": "2ce8aeb8-ebf3-4f28-c678-ebcdd8c6e8f1"
   },
   "outputs": [],
   "source": [
    "conv2d(inputs,kernels,stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b85f26e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b85f26e",
    "outputId": "ce094e04-ecfc-4fc0-b614-e1dbdc2540d6"
   },
   "outputs": [],
   "source": [
    "dilated_conv2d(inputs,kernels,dilation=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0838d",
   "metadata": {
    "id": "7bb0838d"
   },
   "source": [
    "## Task 2: Building and training a ResNet18 model (52%)\n",
    "**Subtasks**\n",
    "1. Figure out the ResNet18 model architecture and write down the dimension of features of each layer (4%).\n",
    "2. Build a ResNet18 model by PyTorch (20%).\n",
    "3. Complete the codes to evaluate and train the model. (10%)\n",
    "4. Viusalize the training curves (2%).\n",
    "5. Point out a potential problem in the training process (2%), propose possible solutions (4%) to improve and implement **at least ONE** of them (10%).\n",
    "\n",
    "Score points:\n",
    "1. The results for subtask 1 is correct.\n",
    "2. The implementation for subtask 2 is correct.\n",
    "3. The implementation for subtask 2 is also concise, i.e., building the network block by block instead of layer by layer.\n",
    "4.\n",
    "5. The two plots for visualization contain all information of interest, one for loss curves and another for accuracy curves.\n",
    "6. The answers to subtask 5 are reasonable and the implementation is correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad4031c",
   "metadata": {
    "id": "0ad4031c"
   },
   "source": [
    "### Prepare packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bb2d7",
   "metadata": {
    "id": "9f4bb2d7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec7314",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91ec7314",
    "outputId": "9a03681e-3b2a-46bc-d60c-3b3bfc917ab4"
   },
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_size = len(train_set)\n",
    "print(train_size)\n",
    "test_size = len(test_set)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cecc458",
   "metadata": {
    "id": "3cecc458"
   },
   "source": [
    "### Define the ResNet18 model\n",
    "\n",
    "Residual Network (ResNet) is a deep learning model widely used for computer vision applications. It is a Convolutional Neural Network (CNN) architecture. ResNet provides an innovative solution to the vanishing gradient problem, known as “residual connections”.\n",
    "\n",
    "ResNet includes multiple \"residual blocks\", each of which contains certain types of layers and residual connections as shown in the figure below.\n",
    "\n",
    "Refer to the paper *[\"Deep Residual Learning for Image Recognition\"](https://arxiv.org/pdf/1512.03385.pdf)* for information about ResNet architecture.\n",
    "\n",
    "Figure out the architecture of ResNet18 and the feature dimension of each layer, considering the input dimension as `(3,32,32)` representing `(C, H, W)`. Write down the architecture and the feature dimension corresponding to each layer in the following markdown cell.\n",
    "\n",
    "Implement to define a ResNet18 model in the following code block.\n",
    "\n",
    "Note that while doing residual connection, if the dimensions of the input and output of the residual block are not the same, we adjust channels and resolution of the input by means of a convolution before adding.\n",
    "\n",
    "![](resnet-block.svg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6147ce",
   "metadata": {},
   "source": [
    "---\n",
    "**Write down your results of the ResNet18 architecture and specify the feature dimension for each layer.**\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc26789",
   "metadata": {
    "id": "dcc26789"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 strides=1):\n",
    "        '''\n",
    "        input_channels: the number of channels of input x.\n",
    "        num_channels: the number of channels channels of the output of the residual block.\n",
    "        strides: the strides for the first convolutional layer in the residual block, \n",
    "                 note that this is not applied to the second convolutional layer in the residual block.\n",
    "        '''\n",
    "        ##############################################################################\n",
    "        # TO DO: Define a ResidualBlock module as the figure shown above.            #\n",
    "        ##############################################################################\n",
    "\n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        ##############################################################################\n",
    "        # TO DO: implement the forward path of the ResidualBlock module.             #\n",
    "        ##############################################################################\n",
    "\n",
    "        \n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a90980",
   "metadata": {
    "id": "a7a90980"
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    ##############################################################################\n",
    "    # TO DO: Define a ResNet18 model and implement its forward path, you may     #\n",
    "    #        also add other functions to this class if necessary.                #\n",
    "    ##############################################################################\n",
    "    # your code\n",
    "\n",
    "        \n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d130b5b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d130b5b1",
    "outputId": "d116ddcc-1d9e-4ec8-e63d-e6a7123b309a"
   },
   "outputs": [],
   "source": [
    "model = ResNet18()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a9c109",
   "metadata": {
    "id": "85a9c109"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba956d73",
   "metadata": {
    "id": "ba956d73"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 256\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Build data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "data_loaders = {\"train\": train_loader, \"test\": test_loader}\n",
    "dataset_sizes = {\"train\": train_size, \"test\": test_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c40ce7",
   "metadata": {
    "id": "94c40ce7"
   },
   "source": [
    "Write a functions to evaluate the model on testing set and train the model for one epoch in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d0326",
   "metadata": {
    "id": "b53d0326"
   },
   "outputs": [],
   "source": [
    "def eval_on_test_set(model):\n",
    "    model.eval()\n",
    "    device = torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    running_accuracy = 0\n",
    "    loss=0\n",
    "\n",
    "    for data in test_loader:\n",
    "        ##############################################################################\n",
    "        # TODO: Implement the evaluation process on test set.                        #\n",
    "        ##############################################################################\n",
    "        # your code\n",
    "\n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "    total_loss=loss/test_size\n",
    "    total_accuracy = running_accuracy / test_size\n",
    "    print('Evaluation  on test set: loss{:.3f} \\t accuracy = {:.2f}%'.format(total_loss, total_accuracy * 100))\n",
    "    model.train()\n",
    "    return total_loss, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462aea7e",
   "metadata": {
    "id": "462aea7e"
   },
   "outputs": [],
   "source": [
    "def train_for_one_epoch(model):\n",
    "    model.train()\n",
    "    # Set up device\n",
    "    device = torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device {device} to train the model.\")\n",
    "    model.to(device)\n",
    "\n",
    "    # set the running quatities to zero at the beginning of the epoch\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        ##############################################################################\n",
    "        # TODO: Implement the training process for one epoch.                        #\n",
    "        ##############################################################################\n",
    "        # your code\n",
    "\n",
    "\n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "\n",
    "    # Compute stats for the full training set\n",
    "    total_loss = running_loss / train_size\n",
    "    total_accuracy = running_accuracy / train_size\n",
    "\n",
    "    return total_loss, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabe5b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffabe5b1",
    "outputId": "d7ef96d9-c89e-4a16-a1f6-bcc779a09bb5"
   },
   "outputs": [],
   "source": [
    "# start training\n",
    "\n",
    "metrics = {\"train_loss\":[], \"train_acc\":[], \"test_loss\":[], \"test_acc\":[]}\n",
    "for epoch in range(epochs):\n",
    "  start=time.time()\n",
    "  train_loss_epoch, train_acc_epoch = train_for_one_epoch(model)\n",
    "  elapsed = (time.time()-start) / 60\n",
    "  print('Training epoch= {} \\t cost_time= {:.2f} min \\t loss= {:.3f} \\t accuracy= {:.2f}%'.format(epoch, elapsed, train_loss_epoch, train_acc_epoch * 100))\n",
    "  test_loss_epoch, test_acc_epoch = eval_on_test_set(model)\n",
    "  metrics['train_loss'].append(train_loss_epoch)\n",
    "  metrics['train_acc'].append(train_acc_epoch)\n",
    "  metrics['test_loss'].append(test_loss_epoch)\n",
    "  metrics['test_acc'].append(test_acc_epoch)\n",
    "\n",
    "# save your trained model for the following question\n",
    "torch.save(model.state_dict(), './model_resnet18.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf18256",
   "metadata": {
    "id": "0bf18256"
   },
   "source": [
    "Visualize the training curves for loss and accuracy in the following code block. Your figure should include two subplots, one for loss curves on training and testing sets, and another for accuracy curves on training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0h001tQKPq_w",
   "metadata": {
    "id": "0h001tQKPq_w"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# TODO: Visualize the loss curves and accuracy curves on training and         #\n",
    "#       testing sets respectively during training.                            #\n",
    "###############################################################################\n",
    "\n",
    "# your code\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iG9yxN-VReRW",
   "metadata": {
    "id": "iG9yxN-VReRW"
   },
   "source": [
    "### Improve the ResNet18 trained above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jQdHY3bgVqEf",
   "metadata": {
    "id": "jQdHY3bgVqEf"
   },
   "source": [
    "Observe the loss and accuracy curves during training and testing respectively, what potential problem can be concluded if continue training the model for further epochs most probably? What kind of techniques can be applied to solve this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KRhf5vVOVtMj",
   "metadata": {
    "id": "KRhf5vVOVtMj"
   },
   "source": [
    "---\n",
    "**Write your observations and analysis in this Markdown cell:**\n",
    "\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BSaYUOtQRsNC",
   "metadata": {
    "id": "BSaYUOtQRsNC"
   },
   "source": [
    "Please choose one technique you mentioned above and implement it, retrain the model, observe and report the loss and accuracy again (10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QLxc7yGKRwv5",
   "metadata": {
    "id": "QLxc7yGKRwv5"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Choose a technique to improve your model.                            #\n",
    "##############################################################################\n",
    "\n",
    "# your code\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EpPWdAT_R16F",
   "metadata": {
    "id": "EpPWdAT_R16F"
   },
   "source": [
    "---\n",
    "**Write your observations and analysis in this Markdown cell:**\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e084bfd",
   "metadata": {
    "id": "3e084bfd"
   },
   "source": [
    "## Task 3: Exploring and explaining the trained model (40%)\n",
    "\n",
    "**Subtasks:**\n",
    "\n",
    "1. Visualize the representations for bottom and top layers by t-SNE, compare and make conclusion (6%).\n",
    "2. Compute saliency map and answer the question about it (6%).\n",
    "3. Compute improved saliency map by SMOOTHGRAD and answer the question about the comparison between the saliency map in subtask 2 and SMOOTHGRAD (10%).\n",
    "4. Design and conduct experiment to explain how CNN works using SMOOTHGRAD (12%).\n",
    "5. Given a model, generate fooling image based on an original image and a target label to fool. Write down the observations from the result (6%).\n",
    "\n",
    "Score points:\n",
    "1. For subtask 1, recognize the correct layers of insterest, extract corresponding intermediate features and make reasonable conclusion.\n",
    "2. For subtask 2, the implementation is correct and as concise as possible and the question is correctly answered.\n",
    "3. For subtask 3, the implementation is correct and as concise as possible and the question is correctly answered.\n",
    "4. For subtask 4, the experiment is reasonably designed and appropriately conducted.\n",
    "5. For subtask 5, the implementation is correct and observation is reasonable.\n",
    "\n",
    "**Note: for task 3, just use the model trained and saved in task 2 part \"define the ResNet18 model\" instead of your improved model in task 2 part \"improve the ResNet18\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y875npg6WpU0",
   "metadata": {
    "id": "Y875npg6WpU0"
   },
   "source": [
    "### Load the trained ResNet18 model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377794e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "377794e5",
    "outputId": "bb5c7df1-b5b8-4350-d888-8e85e794eb82"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "trained_model = ResNet18()\n",
    "assert os.path.exists('./model_resnet18.pt'), 'train the model first'\n",
    "# Load the model trained and saved in task 2 part \"define the ResNet18 model\" \n",
    "trained_model.load_state_dict(torch.load('./model_resnet18.pt', map_location=torch.device('cpu'))) \n",
    "\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
    "trained_model.to(device)\n",
    "trained_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7jIOMxcocHIU",
   "metadata": {
    "id": "7jIOMxcocHIU"
   },
   "source": [
    "### Visualize the learned features for the trained ResNet18 of different layers of model.\n",
    "\n",
    "t-SNE (t-distributed Stochastic Neighbor Embedding) is an unsupervised non-linear dimensionality reduction technique for data exploration and visualizing high-dimensional data. Here, you shall apply t-SNE to the features extracted from a bottom layer and a top layer of the trained ResNet18 model.\n",
    "\n",
    "You should complete:\n",
    "* 1) extract features for the bottom layer and top layer respectively, i.e., the intermediate outputs of these layers.\n",
    "* 2) if the extracted features are in form of feature maps, reshape the feature map for each sample to make it a vector.\n",
    "* 3) visualize the features for the bottom and top layers by t-SNE, observe and analyze the results.\n",
    "\n",
    "The bottom layer is defined as the first max-pooling layer of the whole model; the top layer is defined as the penultimate layer of the whole model. (We refer to the input side as \"bottom\" and the output side as \"top\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OGK1bzp8cUD2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "OGK1bzp8cUD2",
    "outputId": "a809500b-3dd9-4465-c089-bf43edc9fd59"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TO DO: Extract intermediate features of the top and bottom layers          #\n",
    "#        based on your ResNet18 model.                                       #\n",
    "##############################################################################\n",
    "# your code\n",
    "\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "features_top = np.array(features_top) # (10000,512)\n",
    "print(features_top.shape)\n",
    "features_bottom = np.array(features_bottom) # (10000,4096)\n",
    "print(features_bottom.shape)\n",
    "colors_per_class = cm.rainbow(np.linspace(0, 1, 11))\n",
    "\n",
    "# Apply t-SNE to the features\n",
    "features_top_tsne = TSNE(n_components=2, init='pca', random_state=42).fit_transform(features_top)\n",
    "features_bottom_tsne = TSNE(n_components=2, init='pca', random_state=42).fit_transform(features_bottom)\n",
    "\n",
    "# Plot the t-SNE visualization\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Bottom Layer')\n",
    "for label in np.unique(labels):\n",
    "    plt.scatter(features_bottom_tsne[labels == label, 0], features_bottom_tsne[labels == label, 1], label=classes[label], s=5)\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Top Layer')\n",
    "for label in np.unique(labels):\n",
    "    plt.scatter(features_top_tsne[labels == label, 0], features_top_tsne[labels == label, 1], label=classes[label], s=5)\n",
    "plt.legend()\n",
    "plt.gcf().tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lv6rpKnWb9a1",
   "metadata": {
    "id": "lv6rpKnWb9a1"
   },
   "source": [
    "---\n",
    "**Write your observations and analysis in this Markdown cell:**\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b115708",
   "metadata": {
    "id": "3b115708"
   },
   "source": [
    "### Compute saliency map.\n",
    "\n",
    "A saliency map tells us the degree to which each pixel in the image affects the classification score for that image. To compute it, we compute the gradient of the unnormalized score corresponding to the correct class (which is a scalar) with respect to the pixels of the image.\n",
    "\n",
    "Read and understand the paper below, figure out how to compute saliency maps and implement it in the `compute_saliency_maps` function.\n",
    "\n",
    "[Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. \"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\", ICLR Workshop 2014.](https://arxiv.org/pdf/1312.6034.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fnQbAiU2OaGr",
   "metadata": {
    "id": "fnQbAiU2OaGr"
   },
   "outputs": [],
   "source": [
    "### helper function\n",
    "\n",
    "def show_saliency_maps(X, y, saliency):\n",
    "    # Compute saliency maps for images in X\n",
    "\n",
    "    # Convert the saliency map from Torch Tensor to numpy array and show images\n",
    "    # and saliency maps together.\n",
    "    if saliency.dim() == 4:\n",
    "      saliency = saliency.permute(0, 2, 3, 1).numpy()\n",
    "    elif saliency.dim() == 3:\n",
    "      saliency = saliency.numpy()\n",
    "    N = X.shape[0]\n",
    "    for i in range(N):\n",
    "        plt.subplot(2, N, i + 1)\n",
    "        img = np.transpose((X.detach()/2+0.5).numpy(),(0,2,3,1))\n",
    "        plt.imshow(img[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(classes[y.detach().numpy()[i]])\n",
    "        plt.subplot(2, N, N + i + 1)\n",
    "        plt.imshow(saliency[i], cmap=plt.cm.hot)\n",
    "        plt.axis('off')\n",
    "        plt.gcf().set_size_inches(12, 5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlZRGEkCTiKO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "mlZRGEkCTiKO",
    "outputId": "ad010415-4e0f-492b-e74e-16e626d8d7d9"
   },
   "outputs": [],
   "source": [
    "### example images for saliency map and SmoothGrad visualization\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(test_loader)\n",
    "images,labels = next(dataiter)\n",
    "X = images[-3:,:,:,:]\n",
    "y = labels[-3:]\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(X))\n",
    "print('\\t'.join(f'{classes[y[j]]:5s}' for j in range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ckR-ky3riDiU",
   "metadata": {
    "id": "ckR-ky3riDiU"
   },
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; Tensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "\n",
    "    ##############################################################################\n",
    "    # TODO: Implement this function. Perform a forward and backward pass through #\n",
    "    # the model to compute the gradient of the correct class score with respect  #\n",
    "    # to each input image.                                                       #\n",
    "    ##############################################################################\n",
    "    # your code\n",
    "\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3oASx0dtoNH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "d3oASx0dtoNH",
    "outputId": "6d193000-5808-406d-f68e-093cd9a3f82d"
   },
   "outputs": [],
   "source": [
    "saliency = compute_saliency_maps(X.to(device), y.to(device), trained_model)\n",
    "show_saliency_maps(X, y, saliency.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NBzR2FDKqAo3",
   "metadata": {
    "id": "NBzR2FDKqAo3"
   },
   "source": [
    "In order to find an image that maximizes the correct score, we can perform gradient ascent on the input image, can we use the saliency map instead of the gradient we in each step to update the image. Is this assertion true? Why or why not?\n",
    "\n",
    "---\n",
    "**Write your answer and reason in this Markdown cell.**\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-TE9IaG0iD7E",
   "metadata": {
    "id": "-TE9IaG0iD7E"
   },
   "source": [
    "### Obtain improved visualiztion results by SmoothGrad.\n",
    "\n",
    "SmoothGrad is a method that can help visually sharpen gradient-based saliency maps thus improve the visulization quality. *[\"SmoothGrad: removing noise by adding noise\", ICML2017.](https://arxiv.org/pdf/1706.03825.pdf)*\n",
    "\n",
    "\n",
    "Read and understand the paper, implement SmoothGrad and apply **at least ONE** visualization technique mentioned in the paper in the following code block to get better results.\n",
    "\n",
    "You may also refer to this [blog](https://medium.com/@ML-STATS/reducing-noise-and-improving-interpretability-in-cnns-a-technical-review-of-the-smoothgrad-method-da648ee830c6) for concise illustration for SmoothGrad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y87Z85cvpLa_",
   "metadata": {
    "id": "y87Z85cvpLa_"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def compute_smoothgrad(X, y, model, num_samples=50, stdev_spread=0.15):\n",
    "    \"\"\"\n",
    "    Compute smoothed gradients for images in X given model\n",
    "\n",
    "    Inputs:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; Tensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute gradients; see\n",
    "      the torchvision library\n",
    "    - num_samples: An integer; the number of gradient samples to compute for each\n",
    "      input in X.\n",
    "    - stdev_spread: A float; the standard deviation of the Gaussians used to\n",
    "      smooth the gradients.\n",
    "\n",
    "    Returns:\n",
    "    - smoothgrad: saliency: A Tensor of shape (N, 3, H, W) giving the smoothed saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "\n",
    "    ################################################################################\n",
    "    # TODO: Implement this function. Calculate SmoothGrad (smoothed saliency maps) #\n",
    "    #       based on the given parameters for this function.                       #\n",
    "    ################################################################################\n",
    "    # your code\n",
    "\n",
    "\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "\n",
    "    smoothgrad = (smoothgrad - smoothgrad.min()) / (smoothgrad.max() - smoothgrad.min()) # just for better visualization\n",
    "    return smoothgrad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KQqh_Ek5Mccz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "KQqh_Ek5Mccz",
    "outputId": "92aae365-85d3-43c8-f76b-3c764931e03e"
   },
   "outputs": [],
   "source": [
    "smoothgrad = compute_smoothgrad(X.to(device), y.to(device), trained_model)\n",
    "show_saliency_maps(X, y, smoothgrad.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V4HQKHuyU6pG",
   "metadata": {
    "id": "V4HQKHuyU6pG"
   },
   "source": [
    "Compare the results of saliency map and SmoothGrad, what is your discovery? Try to understand the papers to give a reason for the phenomenon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0xrm4anOU0yF",
   "metadata": {
    "id": "0xrm4anOU0yF"
   },
   "source": [
    "---\n",
    "\n",
    "**Write your observations and analysis in this Markdown cell:**\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80U7JYr7S62Z",
   "metadata": {
    "id": "80U7JYr7S62Z"
   },
   "source": [
    "### Design and conduct experiment  to explore and explain how CNN works.\n",
    "\n",
    "Design and conduct one experiment beyond the example images above by utilizing ```compute_smoothgrad```, e.g., compare the SmoothGrad maps of different classes given the same model, compare the SmoothGrad maps of the same class for different models, etc. Please quanlitatively show some evidence (e.g., plotting some examplar images clearly and elegantly) with necessary code snippets, write down your observations and briefly explain.\n",
    "\n",
    "For the experiment you design, please specify:\n",
    "1. What question do you intend to study?\n",
    "2. To study the proposed question, how do you design your experiment?\n",
    "3. What conclusion do you make from the experiment results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X_dX5HbNToJv",
   "metadata": {
    "id": "X_dX5HbNToJv"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TO DO: Design and conduct your experiment.                                 #\n",
    "##############################################################################\n",
    "# your code\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hOwuKz6-UcX2",
   "metadata": {
    "id": "hOwuKz6-UcX2"
   },
   "source": [
    "---\n",
    "\n",
    "**Write your observations and analysis in this Markdown cell:**\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77141694",
   "metadata": {
    "id": "77141694"
   },
   "source": [
    "### Fooling image\n",
    "We can also use image gradients to generate \"fooling images\", that is, given an image and a target class, we can perform gradient ascent over the image to maximize the target class, stopping when the network classifies the image as the target class. Implement the following function to generate fooling images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6ca2e",
   "metadata": {
    "id": "1be6ca2e"
   },
   "outputs": [],
   "source": [
    "def make_fooling_image(X, target_y, model):\n",
    "    \"\"\"\n",
    "    Generate a fooling image that is close to X, but that the model classifies\n",
    "    as target_y.\n",
    "\n",
    "    Inputs:\n",
    "    - X: Input image; Tensor of shape (1, 3, H, W)\n",
    "    - target_y: An integer in the range [0, 10)\n",
    "    - model: A pretrained CNN\n",
    "\n",
    "    Returns:\n",
    "    - X_fooling: An image that is close to X, but that is classifed as target_y\n",
    "    by the model.\n",
    "    \"\"\"\n",
    "    # Initialize our fooling image to the input image, and make it require gradient\n",
    "    X_fooling = X.clone()\n",
    "    X_fooling = X_fooling.requires_grad_()\n",
    "\n",
    "    learning_rate = 1\n",
    "    ##############################################################################\n",
    "    # TODO: Generate a fooling image X_fooling that the model will classify as   #\n",
    "    # the class target_y. You should perform gradient ascent on the score of the #\n",
    "    # target class, stopping when the model is fooled.                           #\n",
    "    # When computing an update step, first normalize the gradient:               #\n",
    "    #   dX = learning_rate * g / ||g||_2                                         #\n",
    "    #                                                                            #\n",
    "    # You should write a training loop.                                          #\n",
    "    #                                                                            #\n",
    "    # HINT: For most examples, you should be able to generate a fooling image    #\n",
    "    # in fewer than 100 iterations of gradient ascent.                           #\n",
    "    # You can print your progress over iterations to check your algorithm.       #\n",
    "    ##############################################################################\n",
    "    \n",
    "    # your code\n",
    "\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    return X_fooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81281231",
   "metadata": {
    "id": "81281231"
   },
   "outputs": [],
   "source": [
    "target_y = 6 # label 'frog'\n",
    "image_to_be_fooled = images[-1:,:,:,:] # an image of plane\n",
    "y = labels[-1:] # label 'plane'\n",
    "\n",
    "X_fooling = make_fooling_image(image_to_be_fooled.to(device), target_y, trained_model.to(device))\n",
    "\n",
    "scores = trained_model(X_fooling)\n",
    "assert target_y == scores.data.max(1)[1][0].item(), 'The model is not fooled!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f3cd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "797f3cd5",
    "outputId": "66df9102-a70a-4547-f8ed-71b31157bf17"
   },
   "outputs": [],
   "source": [
    "org_img = (torch.squeeze(image_to_be_fooled, dim=0).detach().cpu().numpy()) / 2 + 0.5\n",
    "fooling_img = (torch.squeeze(X_fooling, dim = 0).detach().cpu().numpy()) / 2 + 0.5\n",
    "\n",
    "fooling_img.astype(np.uint8)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(org_img.transpose((1, 2, 0)))\n",
    "plt.title(classes[y])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(fooling_img.transpose((1, 2, 0)))\n",
    "plt.title(classes[target_y])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow((org_img - fooling_img).transpose((1, 2, 0)))\n",
    "plt.title('difference')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(10*(org_img - fooling_img).transpose((1, 2, 0)))\n",
    "plt.title('magnified_difference')\n",
    "plt.axis('off')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b8082",
   "metadata": {
    "id": "hOwuKz6-UcX2"
   },
   "source": [
    "Observe the results above and write down your discovery.\n",
    "\n",
    "---\n",
    "\n",
    "**Write your observations and analysis in this Markdown cell:**\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "65696248c9b71dd3c48f2dd2e5b2d3607d9aed1eef8791c3764510e063b61a82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
